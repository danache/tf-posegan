{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bnrc2/mu/tf-posegan\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from tools.img_tf import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from tools.lr import get_lr\n",
    "from tools.keypoint_eval import getScore\n",
    "from tools.ht2coord import getjointcoord\n",
    "from tools.keypoint_eval import load_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "from dataGenerator.datagen_v3 import DataGenerator\n",
    "from hg_models.ian_hourglass import hourglassnet\n",
    "from train_class import train_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_config(conf_file):\n",
    "    params = {}\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(conf_file)\n",
    "    for section in config.sections():\n",
    "        if section == 'DataSetHG':\n",
    "            for option in config.options(section):\n",
    "                params[option] = eval(config.get(section, option))\n",
    "        if section == 'log':\n",
    "            for option in config.options(section):\n",
    "                params[option] = eval(config.get(section, option))\n",
    "        if section == 'Saver':\n",
    "            for option in config.options(section):\n",
    "                params[option] = eval(config.get(section, option))\n",
    "        if section == 'Training setting':\n",
    "            for option in config.options(section):\n",
    "                params[option] = eval(config.get(section, option))\n",
    "    return params\n",
    "\n",
    "def process_network(conf_file):\n",
    "    params = {}\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(conf_file)\n",
    "    for section in config.sections():\n",
    "\n",
    "        for option in config.options(section):\n",
    "            params[option] = eval(config.get(section, option))\n",
    "    return params\n",
    "params = process_config('./config/config.cfg')\n",
    "network_params = process_network(\"./config/hourglass.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING TRAIN DATA\n",
      "SET CREATED\n",
      "--Training set : 377616  samples.\n",
      "READING TRAIN DATA\n",
      "SET CREATED\n",
      "--Training set : 26390  samples.\n",
      "(16, 256, 256, 3)\n",
      "(16, 64, 64, 14)\n",
      "GPU??????????\n",
      "[0, 1]\n",
      "/gpu:0\n",
      "(?, 64, 64, 14)\n",
      "(?, 64, 64, 14)\n",
      "/gpu:1\n",
      "(?, 64, 64, 14)\n",
      "(?, 64, 64, 14)\n",
      "<zip object at 0x7fc287b256c8>\n",
      "<zip object at 0x7fc287b256c8>\n"
     ]
    }
   ],
   "source": [
    "params = process_config('./config/config.cfg')\n",
    "network_params = process_network(\"./config/hourglass.cfg\")\n",
    "###\n",
    "model = hourglassnet()\n",
    "###\n",
    "train_data = DataGenerator(imgdir=params[\"train_img_path\"], txt=\"/media/bnrc2/_backup/dataset/aiclg/data.txt\", batch_size=params['batch_size'], is_aug=False,\n",
    "                           joints_name=\n",
    "                           params[\"joints\"])  # , refine_num = 10000)\n",
    "valid_data = DataGenerator(imgdir=params[\"valid_img_path\"], txt=\"/media/bnrc2/_backup/dataset/aiclg/valid.txt\", batch_size=params['batch_size'], is_aug=False,\n",
    "                           joints_name=\n",
    "                           params[\"joints\"],isTraing=False)\n",
    "valid_gen = valid_data.get_batch_generator()\n",
    "img_valid, gt_valid,  name_valid, center_valid, scale_valid = next(\n",
    "                                valid_gen)\n",
    "print(img_valid.shape)\n",
    "print(gt_valid.shape)\n",
    "# print(name_valid.shape)\n",
    "# print(center_valid.shape)\n",
    "# print(scale_valid.shape)\n",
    "# exit(-1)\n",
    "train_log_dir = \"/media/bnrc2/_backup/log/self-gan/GAN2GPU/train.log\"\n",
    "valid_log_dir = \"/media/bnrc2/_backup/log/self-gan/GAN2GPU/valid.log\"\n",
    "trainer = train_class(model, nstack=network_params['nstack'], batch_size=params['batch_size'],\n",
    "                              learn_rate=params['lear_rate'], decay=params['decay'],\n",
    "                              decay_step=params['decay_step'],logdir_train=train_log_dir,\n",
    "                              logdir_valid=valid_log_dir,name='gan',\n",
    "                               train_record=train_data,valid_record=valid_data,\n",
    "                              save_model_dir=params['model_save_path'],\n",
    "                              resume=\"/media/bnrc2/_backup/models/gan2gpu/gan_1\",\n",
    "                              gpu=[0,1],partnum=network_params['partnum'],\n",
    "                              val_label=params['valid_label'],train_label=params['label_dir'],\n",
    "                      human_decay=params['human_decay'],\n",
    "                     )\n",
    "trainer.generateModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = valid_data.get_batch_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session initialization\n",
      "init done\n",
      "resume from/media/bnrc2/_backup/models/gan2gpu/gan_1\n",
      "INFO:tensorflow:Restoring parameters from /media/bnrc2/_backup/models/gan2gpu/gan_1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'train_class' object has no attribute 'valid_gen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ea6781b26adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mu/tf-posegan/train_class.py\u001b[0m in \u001b[0;36mtest_init\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    377\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume from\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalStep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshowStep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Session'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mu/tf-posegan/train_class.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             img_valid, gt_valid, name_valid, center_valid, scale_valid = next(\n\u001b[0;32m--> 406\u001b[0;31m                 self.valid_gen)\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mval_percent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_batch_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'train_class' object has no attribute 'valid_gen'"
     ]
    }
   ],
   "source": [
    "trainer.test_init(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________\n",
      "score = 0.0\n",
      "________________________________\n"
     ]
    }
   ],
   "source": [
    "val_begin = time.time()\n",
    "valid_anno = load_annotations(params['valid_label'])\n",
    "valid_predictions = dict()\n",
    "valid_predictions['image_ids'] = []\n",
    "valid_predictions['annos'] = dict()\n",
    "\n",
    "for v in range(10):  # valid_iter\n",
    "\n",
    "    img_valid, gt_valid, name_valid, center_valid, scale_valid = next(\n",
    "        valid_gen)\n",
    "\n",
    "\n",
    "    valid_out = trainer.Session.run(\n",
    "        trainer.valid_output, feed_dict={trainer.valid_img: img_valid, trainer.valid_ht:\n",
    "            gt_valid}\n",
    "    )\n",
    "\n",
    "    # print(np.array(accuracy_pred).shape)\n",
    "    # valid_predictions = getjointcoord(val_cord, val_name, valid_predictions)\n",
    "    vadli_coord = trainer.train_record.recoverFromHm(hm=valid_out, center=center_valid,\n",
    "                                                  scale=scale_valid)\n",
    "    valid_predictions = getjointcoord(vadli_coord, name_valid, valid_predictions)\n",
    "\n",
    "score = getScore(valid_predictions, valid_anno)\n",
    "print(\"________________________________\")\n",
    "print(\"score = \" + str(score))\n",
    "print(\"________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keypoint_eval(predictions, annotations):\n",
    "    oks_all = []\n",
    "    oks_num = 0\n",
    "\n",
    "    # Construct set to speed up id searching.\n",
    "    prediction_id_set = set(predictions['image_ids'])\n",
    "    # for every annotation in our test/validation set\n",
    "    for image_id in annotations['image_ids']:\n",
    "        # if the image in the predictions, then compute oks\n",
    "        if image_id in prediction_id_set:\n",
    "\n",
    "            oks = compute_oks(anno=annotations['annos'][image_id], \\\n",
    "                              predict=predictions['annos'][image_id]['keypoint_annos'], \\\n",
    "                              delta=annotations['delta'])\n",
    "            # view pairs with max OKSs as match ones, add to oks_all\n",
    "\n",
    "            oks_all.append( np.max(oks))\n",
    "\n",
    "            # accumulate total num by max(gtN,pN)\n",
    "            oks_num += 1  # np.max(oks.shape)\n",
    "        # else:\n",
    "\n",
    "            # otherwise report warning\n",
    "            #return_dict['warning'].append(image_id + ' is not in the prediction JSON file.')\n",
    "            # # number of humen in ground truth annotations\n",
    "            # gt_n = len(annotations['annos'][image_id]['human_annos'].keys())\n",
    "            # # fill 0 in oks scores\n",
    "            # oks_all = np.concatenate((oks_all, np.zeros((gt_n))), axis=0)\n",
    "            # # accumulate total num by ground truth number\n",
    "            # oks_num += gt_n\n",
    "\n",
    "    # compute mAP by APs under different oks thresholds\n",
    "    average_precision = []\n",
    "    oks_all = np.array(oks_all)\n",
    "    print(oks_all)\n",
    "    # for threshold in np.linspace(0.1, 0.5, 10):\n",
    "    #     average_precision.append(np.sum(oks_all > threshold) / np.float32(oks_num))\n",
    "    average_precision.append(np.sum(oks_all > 0.5) / np.float32(oks_num))\n",
    "    #average_precision.append(np.sum(oks_all > 0.5) / np.float32(oks_num))\n",
    "    #return_dict['score'] = np.mean(average_precision)\n",
    "    \n",
    "    return np.mean(average_precision)#return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_oks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9cc809d978d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeypoint_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_predictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_anno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-955fda52b758>\u001b[0m in \u001b[0;36mkeypoint_eval\u001b[0;34m(predictions, annotations)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction_id_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_oks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                               \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keypoint_annos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                               \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m# view pairs with max OKSs as match ones, add to oks_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_oks' is not defined"
     ]
    }
   ],
   "source": [
    "score = keypoint_eval(valid_predictions,valid_anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keypoint_annos': {'human1': array([[ 853.,  309.,    0.],\n",
       "         [ 912.,  342.,    0.],\n",
       "         [ 903.,  438.,    0.],\n",
       "         [ 892.,  331.,    0.],\n",
       "         [ 849.,  483.,    0.],\n",
       "         [ 939.,  348.,    0.],\n",
       "         [ 909.,  241.,    0.],\n",
       "         [ 889.,  252.,    0.],\n",
       "         [ 856.,  258.,    0.],\n",
       "         [ 844.,  376.,    0.],\n",
       "         [ 855.,  512.,    0.],\n",
       "         [ 880.,  331.,    0.],\n",
       "         [ 876.,  320.,    0.],\n",
       "         [ 912.,  433.,    0.]])}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_predictions[\"annos\"]['3b7d8060cf3d110ee6c8225895bfb60f494db760']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in valid_anno['annos']:\n",
    "    if '3b7d8060cf3d110ee6c8225895bfb60f494db760' in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/media/bnrc2/_backup/ai/ai_challenger_keypoint_validation_20170911/keypoint_validation_annotations_20170911.json\") as f:\n",
    "    js = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'http://images.china.cn/attachement/jpg/site1000/20150415/c03fd55e3b6d169887495d.JPG', 'human_annotations': {'human2': [398, 198, 532, 548], 'human3': [830, 185, 945, 546], 'human1': [129, 148, 269, 556]}, 'image_id': '3b7d8060cf3d110ee6c8225895bfb60f494db760', 'keypoint_annotations': {'human2': [420, 280, 1, 416, 323, 1, 436, 294, 1, 487, 267, 1, 503, 319, 1, 469, 329, 1, 451, 385, 1, 443, 452, 1, 466, 512, 1, 495, 384, 1, 516, 427, 1, 510, 509, 1, 451, 211, 1, 445, 267, 1], 'human3': [865, 264, 1, 855, 329, 2, 848, 328, 2, 0, 0, 3, 0, 0, 3, 0, 0, 3, 884, 368, 1, 895, 450, 1, 907, 516, 1, 916, 361, 1, 931, 444, 1, 937, 523, 1, 893, 195, 1, 897, 241, 1], 'human1': [149, 228, 1, 162, 281, 1, 206, 262, 1, 222, 230, 2, 234, 288, 1, 256, 294, 2, 174, 356, 1, 166, 445, 1, 151, 528, 1, 216, 358, 1, 208, 448, 1, 200, 523, 1, 209, 161, 1, 191, 211, 1]}}\n"
     ]
    }
   ],
   "source": [
    "for i in js:\n",
    "    if i[\"image_id\"] == '3b7d8060cf3d110ee6c8225895bfb60f494db760':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['delta', 'image_ids', 'annos'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'anno'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6c0b2e457f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_anno\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_anno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_anno\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"anno\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'anno'"
     ]
    }
   ],
   "source": [
    "for i in valid_anno:\n",
    "    print(valid_anno.keys())\n",
    "    print(valid_anno[\"anno\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf14]",
   "language": "python",
   "name": "conda-env-tf14-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
